{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherExtractor:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    def fetch_weather(self, location):\n",
    "        params = {\n",
    "            \"q\": location,\n",
    "            \"appid\": self.api_key,\n",
    "            \"units\": \"metric\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(self.base_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            weather = {\n",
    "                \"location\": data.get(\"name\"),\n",
    "                \"temperature\": data[\"main\"][\"temp\"],\n",
    "                \"humidity\": data[\"main\"][\"humidity\"],\n",
    "                \"condition\": data[\"weather\"][0][\"description\"],\n",
    "                \"wind_speed\": data[\"wind\"][\"speed\"]\n",
    "            }\n",
    "            return weather\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return {\"error\": str(e)}\n",
    "        except KeyError:\n",
    "            return {\"error\": \"Unexpected response format.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f83974",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(input: str) -> str:\n",
    "    \"\"\"Safe calculator for arithmetic expressions.\"\"\"\n",
    "    try:\n",
    "        allowed = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed for c in input.replace(\" \", \"\")):\n",
    "            return \"Error: Only numbers and + - * / ( ) are allowed\"\n",
    "        if \"__\" in input or \"import\" in input.lower():\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        result = eval(input)\n",
    "        return f\"Calculation: {input} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def weather_tool(location: str) -> str:\n",
    "    \"\"\"Fetches current weather for the given location using OpenWeather API.\"\"\"\n",
    "    extractor = WeatherExtractor(api_key=\"2aee399e577605decba2ad78d68831a7\") \n",
    "    weather = extractor.fetch_weather(location)\n",
    "    if \"error\" in weather:\n",
    "        return f\"Error fetching weather: {weather['error']}\"\n",
    "    return (f\"Weather in {weather['location']}: {weather['temperature']}¬∞C, \"\n",
    "            f\"{weather['condition']}, Humidity: {weather['humidity']}%, Wind Speed: {weather['wind_speed']} m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644da1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fashion_tool(user_query: str) -> str:\n",
    "    \"\"\"Provides fashion advice and trends based on the user's query.\"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        google_api_key=\"AIzaSyC-YjySMtVWFcA2NDRyNSodW8tXMH475as\", \n",
    "        temperature=0.3\n",
    "    )\n",
    "    prompt = (f\"You are a fashion expert assistant.\\nUser asked: {user_query}\\n\"\n",
    "              f\"Reply ONLY with relevant fashion trends, clothing advice or styles related to the query.\")\n",
    "    return llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=\"AIzaSyC-YjySMtVWFcA2NDRyNSodW8tXMH475as\",\n",
    "    temperature=0.3\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2788a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "    \"calculator\": calculator,\n",
    "    \"weather_tool\": weather_tool,\n",
    "    \"fashion_tool\": fashion_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb8c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_history(user_input: str) -> str:\n",
    "    \"\"\"Construct prompt for Gemini with conversation history included manually.\"\"\"\n",
    "    chat_history = memory.load_memory_variables({})[\"chat_history\"]  # List of messages\n",
    "    prompt = \"\"\n",
    "    for msg in chat_history:\n",
    "        # msg is a langchain.schema.HumanMessage or AIMessage\n",
    "        if hasattr(msg, \"type\"):\n",
    "            # Older versions might have 'type' attribute\n",
    "            if msg.type == \"human\":\n",
    "                prompt += f\"User: {msg.content}\\n\"\n",
    "            elif msg.type == \"ai\":\n",
    "                prompt += f\"AI: {msg.content}\\n\"\n",
    "        else:\n",
    "            # fallback by class name\n",
    "            from langchain.schema import HumanMessage, AIMessage\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                prompt += f\"User: {msg.content}\\n\"\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                prompt += f\"AI: {msg.content}\\n\"\n",
    "    prompt += f\"User: {user_input}\\nAI:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc27d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tools_if_needed(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if the user_input should call any tool based on keywords,\n",
    "    and invoke that tool directly.\n",
    "    \"\"\"\n",
    "    user_input_lower = user_input.lower()\n",
    "    # Very basic logic to detect intent\n",
    "    if any(word in user_input_lower for word in [\"calculate\", \"calc\", \"+\", \"-\", \"*\", \"/\"]):\n",
    "        return calculator(user_input)\n",
    "    if \"weather\" in user_input_lower:\n",
    "        # Extract location after 'in' if present\n",
    "        import re\n",
    "        match = re.search(r\"weather in ([a-zA-Z\\s]+)\", user_input_lower)\n",
    "        location = match.group(1).strip() if match else user_input\n",
    "        return weather_tool(location)\n",
    "    if any(word in user_input_lower for word in [\"fashion\", \"clothes\", \"style\", \"dress\"]):\n",
    "        return fashion_tool(user_input)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"ü§ñ Multi-tool AI Bot (calculator, weather, fashion) - type 'quit' to exit\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Check if any tool should be called directly\n",
    "        tool_response = invoke_tools_if_needed(user_input)\n",
    "        if tool_response:\n",
    "            print(f\"ü§ñ Bot: {tool_response}\")\n",
    "            # Save to memory manually for tool output\n",
    "            memory.save_context({\"input\": user_input}, {\"output\": tool_response})\n",
    "            continue\n",
    "\n",
    "        # Otherwise, handle as normal chat with full history prompt\n",
    "        prompt = build_prompt_with_history(user_input)\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            print(f\"ü§ñ Bot: {response}\")\n",
    "            memory.save_context({\"input\": user_input}, {\"output\": response})\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
